

<!DOCTYPE html>
<!--[if IE 8]><html class="no-js lt-ie9" lang="en" > <![endif]-->
<!--[if gt IE 8]><!--> <html class="no-js" lang="en" > <!--<![endif]-->
<head>
  <meta charset="utf-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  
  <title>moe.optimal_learning.EPI.src.python.models package &mdash; MOE 0.1.0 documentation</title>
  

  
  
    <link rel="shortcut icon" href="_static/favicon.ico"/>
  

  
  <link href='https://fonts.googleapis.com/css?family=Lato:400,700|Roboto+Slab:400,700|Inconsolata:400,700' rel='stylesheet' type='text/css'>

  
  
    

  

  
  
    <link rel="stylesheet" href="_static/css/theme.css" type="text/css" />
  

  
    <link rel="stylesheet" href="_static/breathe.css" type="text/css" />
  
    <link rel="top" title="MOE 0.1.0 documentation" href="index.html"/>
        <link rel="up" title="moe.optimal_learning.EPI.src.python package" href="moe.optimal_learning.EPI.src.python.html"/>
        <link rel="next" title="moe.tests package" href="moe.tests.html"/>
        <link rel="prev" title="moe.optimal_learning.EPI.src.python.lib package" href="moe.optimal_learning.EPI.src.python.lib.html"/> 

  
  <script src="https://cdnjs.cloudflare.com/ajax/libs/modernizr/2.6.2/modernizr.min.js"></script>

</head>

<body class="wy-body-for-nav" role="document">

  <div class="wy-grid-for-nav">

    
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-nav-search">
        <a href="index.html" class="fa fa-home"> MOE</a>
        <div role="search">
  <form id ="rtd-search-form" class="wy-form" action="search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>
      </div>

      <div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="main navigation">
        
        
            <ul class="current">
<li class="toctree-l1 current"><a class="reference internal" href="moe.html">moe package</a><ul class="current">
<li class="toctree-l2 current"><a class="reference internal" href="moe.html#subpackages">Subpackages</a></li>
<li class="toctree-l2"><a class="reference internal" href="moe.html#submodules">Submodules</a></li>
<li class="toctree-l2"><a class="reference internal" href="moe.html#module-moe.resources">moe.resources module</a></li>
<li class="toctree-l2"><a class="reference internal" href="moe.html#module-moe">Module contents</a></li>
</ul>
</li>
</ul>
<ul>
<li class="toctree-l1"><a class="reference internal" href="gpp_math_hpp.html">gpp_math.hpp</a></li>
<li class="toctree-l1"><a class="reference internal" href="gpp_geometry_hpp.html">gpp_geometry.hpp</a></li>
</ul>

        
      </div>
      &nbsp;
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap">

      
      <nav class="wy-nav-top" role="navigation" aria-label="top navigation">
        <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
        <a href="index.html">MOE</a>
      </nav>


      
      <div class="wy-nav-content">
        <div class="rst-content">
          <div role="navigation" aria-label="breadcrumbs navigation">
  <ul class="wy-breadcrumbs">
    <li><a href="index.html">Docs</a> &raquo;</li>
      
          <li><a href="moe.html">moe package</a> &raquo;</li>
      
          <li><a href="moe.optimal_learning.html">moe.optimal_learning package</a> &raquo;</li>
      
          <li><a href="moe.optimal_learning.EPI.html">moe.optimal_learning.EPI package</a> &raquo;</li>
      
          <li><a href="moe.optimal_learning.EPI.src.html">moe.optimal_learning.EPI.src package</a> &raquo;</li>
      
          <li><a href="moe.optimal_learning.EPI.src.python.html">moe.optimal_learning.EPI.src.python package</a> &raquo;</li>
      
    <li>moe.optimal_learning.EPI.src.python.models package</li>
      <li class="wy-breadcrumbs-aside">
        
          <a href="_sources/moe.optimal_learning.EPI.src.python.models.txt" rel="nofollow"> View page source</a>
        
      </li>
  </ul>
  <hr/>
</div>
          <div role="main">
            
  <div class="section" id="moe-optimal-learning-epi-src-python-models-package">
<h1>moe.optimal_learning.EPI.src.python.models package<a class="headerlink" href="#moe-optimal-learning-epi-src-python-models-package" title="Permalink to this headline">¶</a></h1>
<div class="section" id="submodules">
<h2>Submodules<a class="headerlink" href="#submodules" title="Permalink to this headline">¶</a></h2>
</div>
<div class="section" id="module-moe.optimal_learning.EPI.src.python.models.covariance_of_process">
<span id="moe-optimal-learning-epi-src-python-models-covariance-of-process-module"></span><h2>moe.optimal_learning.EPI.src.python.models.covariance_of_process module<a class="headerlink" href="#module-moe.optimal_learning.EPI.src.python.models.covariance_of_process" title="Permalink to this headline">¶</a></h2>
<dl class="class">
<dt id="moe.optimal_learning.EPI.src.python.models.covariance_of_process.CovarianceOfProcess">
<em class="property">class </em><tt class="descclassname">moe.optimal_learning.EPI.src.python.models.covariance_of_process.</tt><tt class="descname">CovarianceOfProcess</tt><big>(</big><em>cov_func=None</em>, <em>grad_cov_func=None</em>, <em>hyperparameters=</em>, <span class="optional">[</span><span class="optional">]</span><em>hyperparameter_grad_table=</em>, <span class="optional">[</span><span class="optional">]</span><em>hyperparameter_grad_table_kwargs=</em><span class="optional">[</span><span class="optional">]</span><big>)</big><a class="reference internal" href="_modules/moe/optimal_learning/EPI/src/python/models/covariance_of_process.html#CovarianceOfProcess"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#moe.optimal_learning.EPI.src.python.models.covariance_of_process.CovarianceOfProcess" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <tt class="xref py py-class docutils literal"><span class="pre">object</span></tt></p>
<p>The covariance properties of a process</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Kwargs:</th><td class="field-body"><ul class="first">
<li><dl class="first docutils">
<dt>cov_func: The covariance function, a function of two input points</dt>
<dd><p class="first last">default: <span class="math">\(cov(x_1, x_2) = a*exp(-(1/2l)*|x_1 - x_2|^p)\)</span></p>
</dd>
</dl>
</li>
<li><dl class="first docutils">
<dt>grad_cov_func: The gradient of the covariance function, a function of two input points.</dt>
<dd><p class="first last">The gradient is taken with respect to the first point.</p>
</dd>
</dl>
</li>
<li><p class="first">hyperparameter_grad_table: a mapping from hyperparameters to gradients of covariance wrt them</p>
</li>
<li><dl class="first docutils">
<dt>length, alpha: Parameters of the default square exponential covariance function.</dt>
<dd><p class="first last">Not used if explicit <em>cov</em> and <em>grad_cov</em> functions are given.</p>
</dd>
</dl>
</li>
</ul>
</td>
</tr>
<tr class="field-even field"><th class="field-name" colspan="2">State functions:</th></tr>
<tr class="field-even field"><td>&nbsp;</td><td class="field-body"><ul class="first simple">
<li>self.cov(x1, x2): The covariance function of the process</li>
<li>self.grad_cov(x1, x2): The gradient of the covariance function of the process</li>
</ul>
</td>
</tr>
<tr class="field-odd field"><th class="field-name">References:</th><td class="field-body"><ul class="first last simple">
<li>www.gaussianprocess.org/gpml/chapters/RW.pdf (most notably chapter 5)</li>
</ul>
</td>
</tr>
</tbody>
</table>
<dl class="method">
<dt id="moe.optimal_learning.EPI.src.python.models.covariance_of_process.CovarianceOfProcess.update_hyperparameters">
<tt class="descname">update_hyperparameters</tt><big>(</big><em>GP</em>, <em>update_type='bfgs_marginal_likelihood_updater'</em>, <em>**kwargs</em><big>)</big><a class="reference internal" href="_modules/moe/optimal_learning/EPI/src/python/models/covariance_of_process.html#CovarianceOfProcess.update_hyperparameters"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#moe.optimal_learning.EPI.src.python.models.covariance_of_process.CovarianceOfProcess.update_hyperparameters" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

</dd></dl>

</div>
<div class="section" id="module-moe.optimal_learning.EPI.src.python.models.gaussian_process">
<span id="moe-optimal-learning-epi-src-python-models-gaussian-process-module"></span><h2>moe.optimal_learning.EPI.src.python.models.gaussian_process module<a class="headerlink" href="#module-moe.optimal_learning.EPI.src.python.models.gaussian_process" title="Permalink to this headline">¶</a></h2>
<dl class="class">
<dt id="moe.optimal_learning.EPI.src.python.models.gaussian_process.GaussianProcess">
<em class="property">class </em><tt class="descclassname">moe.optimal_learning.EPI.src.python.models.gaussian_process.</tt><tt class="descname">GaussianProcess</tt><big>(</big><em>domain=None</em>, <em>covariance_of_process=None</em>, <em>initial_best_so_far=1.7976931348623157e+308</em>, <em>default_sample_variance=0.0</em>, <em>max_number_of_threads=1</em><big>)</big><a class="reference internal" href="_modules/moe/optimal_learning/EPI/src/python/models/gaussian_process.html#GaussianProcess"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#moe.optimal_learning.EPI.src.python.models.gaussian_process.GaussianProcess" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <tt class="xref py py-class docutils literal"><span class="pre">object</span></tt></p>
<p>A gaussian process of a sample function</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Attributes:</th><td class="field-body"><ul class="first">
<li><dl class="first docutils">
<dt>cop: The <em>covariance_of_process</em> a CovarianceOfProcess object</dt>
<dd><p class="first last">default: <em>cop=CovarianceOfProcess()</em></p>
</dd>
</dl>
</li>
<li><dl class="first docutils">
<dt>domain: the domain to optimize over,</dt>
<dd><p class="first last">if no domain is passed in it will search over all real numbers</p>
</dd>
</dl>
</li>
<li><p class="first">initial_best_so_far: initial value of best_so_far: numpy.min(values_of_samples) if samples exist, o/w max double</p>
</li>
<li><p class="first">default_sample_variance: noise variance to use if no noise is explicitly specified</p>
</li>
<li><p class="first">max_number_of_threads: max number of threads to use; only applicable to LinkedCpp subclass</p>
</li>
</ul>
</td>
</tr>
<tr class="field-even field"><th class="field-name" colspan="2">Internal state variables:</th></tr>
<tr class="field-even field"><td>&nbsp;</td><td class="field-body"><ul class="first last simple">
<li>domain: the domain of the function</li>
<li>cholesky_L: see paper</li>
<li>cholesky_alpha: see paper</li>
<li>points_sampled: The SamplePoint(s) sampled thus far</li>
<li>values_of_samples: The values of points sampled thus far in a list</li>
<li>best_so_far: numpy.min(values_of_samples) or <em>initial_best_so_far</em> if no points sampled</li>
</ul>
</td>
</tr>
</tbody>
</table>
<dl class="method">
<dt id="moe.optimal_learning.EPI.src.python.models.gaussian_process.GaussianProcess.add_sample_point">
<tt class="descname">add_sample_point</tt><big>(</big><em>sample_point</em>, <em>sample_variance=None</em><big>)</big><a class="reference internal" href="_modules/moe/optimal_learning/EPI/src/python/models/gaussian_process.html#GaussianProcess.add_sample_point"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#moe.optimal_learning.EPI.src.python.models.gaussian_process.GaussianProcess.add_sample_point" title="Permalink to this definition">¶</a></dt>
<dd><p>Add a SamplePoint <em>sample_point</em> to the GPP</p>
</dd></dl>

<dl class="method">
<dt id="moe.optimal_learning.EPI.src.python.models.gaussian_process.GaussianProcess.build_covariance_matrix">
<tt class="descname">build_covariance_matrix</tt><big>(</big><em>grad_function=None</em>, <em>kwargs={}</em><big>)</big><a class="reference internal" href="_modules/moe/optimal_learning/EPI/src/python/models/gaussian_process.html#GaussianProcess.build_covariance_matrix"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#moe.optimal_learning.EPI.src.python.models.gaussian_process.GaussianProcess.build_covariance_matrix" title="Permalink to this definition">¶</a></dt>
<dd><p>build covariance matrix for inputs, see paper</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Returns:</th><td class="field-body">2-D numpy array</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt id="moe.optimal_learning.EPI.src.python.models.gaussian_process.GaussianProcess.build_grad_K_star">
<tt class="descname">build_grad_K_star</tt><big>(</big><em>points_to_sample</em><big>)</big><a class="reference internal" href="_modules/moe/optimal_learning/EPI/src/python/models/gaussian_process.html#GaussianProcess.build_grad_K_star"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#moe.optimal_learning.EPI.src.python.models.gaussian_process.GaussianProcess.build_grad_K_star" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="method">
<dt id="moe.optimal_learning.EPI.src.python.models.gaussian_process.GaussianProcess.build_grad_sample_covariance_matrix">
<tt class="descname">build_grad_sample_covariance_matrix</tt><big>(</big><em>points_to_sample</em><big>)</big><a class="reference internal" href="_modules/moe/optimal_learning/EPI/src/python/models/gaussian_process.html#GaussianProcess.build_grad_sample_covariance_matrix"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#moe.optimal_learning.EPI.src.python.models.gaussian_process.GaussianProcess.build_grad_sample_covariance_matrix" title="Permalink to this definition">¶</a></dt>
<dd><p>Grad covariance of points to sample, see paper</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Returns:</th><td class="field-body">3-D list</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt id="moe.optimal_learning.EPI.src.python.models.gaussian_process.GaussianProcess.build_mix_covariance_matrix">
<tt class="descname">build_mix_covariance_matrix</tt><big>(</big><em>points_to_sample</em><big>)</big><a class="reference internal" href="_modules/moe/optimal_learning/EPI/src/python/models/gaussian_process.html#GaussianProcess.build_mix_covariance_matrix"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#moe.optimal_learning.EPI.src.python.models.gaussian_process.GaussianProcess.build_mix_covariance_matrix" title="Permalink to this definition">¶</a></dt>
<dd><p>Covariance matrix of points to sample vs points sampled already, see paper</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Returns:</th><td class="field-body">2-D numpy array</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt id="moe.optimal_learning.EPI.src.python.models.gaussian_process.GaussianProcess.build_sample_covariance_matrix">
<tt class="descname">build_sample_covariance_matrix</tt><big>(</big><em>points_to_sample</em><big>)</big><a class="reference internal" href="_modules/moe/optimal_learning/EPI/src/python/models/gaussian_process.html#GaussianProcess.build_sample_covariance_matrix"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#moe.optimal_learning.EPI.src.python.models.gaussian_process.GaussianProcess.build_sample_covariance_matrix" title="Permalink to this definition">¶</a></dt>
<dd><p>Covariance of points to sample, see paper</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Returns:</th><td class="field-body">2-D numpy array</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt id="moe.optimal_learning.EPI.src.python.models.gaussian_process.GaussianProcess.cholesky_decomp_and_grad">
<tt class="descname">cholesky_decomp_and_grad</tt><big>(</big><em>points_to_sample</em>, <em>var_of_grad=0</em>, <em>eps=1e-06</em><big>)</big><a class="reference internal" href="_modules/moe/optimal_learning/EPI/src/python/models/gaussian_process.html#GaussianProcess.cholesky_decomp_and_grad"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#moe.optimal_learning.EPI.src.python.models.gaussian_process.GaussianProcess.cholesky_decomp_and_grad" title="Permalink to this definition">¶</a></dt>
<dd><p>Get the cholesky decomposition of the variance and its gradient</p>
<p>see S.P.Smith; <em>Differentiation of the Cholesky Algorithm</em>; 1995</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Returns:</th><td class="field-body">2-D numpy array, n-D numpy array</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt id="moe.optimal_learning.EPI.src.python.models.gaussian_process.GaussianProcess.get_grad_cov_component">
<tt class="descname">get_grad_cov_component</tt><big>(</big><em>points_to_sample</em>, <em>i</em>, <em>j</em>, <em>var</em><big>)</big><a class="reference internal" href="_modules/moe/optimal_learning/EPI/src/python/models/gaussian_process.html#GaussianProcess.get_grad_cov_component"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#moe.optimal_learning.EPI.src.python.models.gaussian_process.GaussianProcess.get_grad_cov_component" title="Permalink to this definition">¶</a></dt>
<dd><p>Get a specific component (i,j) of the grad cholesky decomposition of the variance
w.r.t the variable (in points_to_sample) var</p>
<p>This is expensive to do for all combos O(2*L^2*N^2) and should be offloaded to C (length = size points_to_sample, N = size_of_sampled)</p>
<p>see S.P.Smith; <em>Differentiation of the Cholesky Algorithm</em>; 1995</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Returns:</th><td class="field-body">2-D numpy array, n-D numpy array</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt id="moe.optimal_learning.EPI.src.python.models.gaussian_process.GaussianProcess.get_grad_mu">
<tt class="descname">get_grad_mu</tt><big>(</big><em>points_to_sample</em><big>)</big><a class="reference internal" href="_modules/moe/optimal_learning/EPI/src/python/models/gaussian_process.html#GaussianProcess.get_grad_mu"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#moe.optimal_learning.EPI.src.python.models.gaussian_process.GaussianProcess.get_grad_mu" title="Permalink to this definition">¶</a></dt>
<dd><p>Returns the gradient of the mean of the GPP at <em>points_to_sample</em></p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Returns:</th><td class="field-body">1-D numpy array</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt id="moe.optimal_learning.EPI.src.python.models.gaussian_process.GaussianProcess.get_log_marginal_likelihood">
<tt class="descname">get_log_marginal_likelihood</tt><big>(</big><big>)</big><a class="reference internal" href="_modules/moe/optimal_learning/EPI/src/python/models/gaussian_process.html#GaussianProcess.get_log_marginal_likelihood"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#moe.optimal_learning.EPI.src.python.models.gaussian_process.GaussianProcess.get_log_marginal_likelihood" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="method">
<dt id="moe.optimal_learning.EPI.src.python.models.gaussian_process.GaussianProcess.get_mean_and_var_of_points">
<tt class="descname">get_mean_and_var_of_points</tt><big>(</big><em>points_to_sample</em><big>)</big><a class="reference internal" href="_modules/moe/optimal_learning/EPI/src/python/models/gaussian_process.html#GaussianProcess.get_mean_and_var_of_points"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#moe.optimal_learning.EPI.src.python.models.gaussian_process.GaussianProcess.get_mean_and_var_of_points" title="Permalink to this definition">¶</a></dt>
<dd><p>Given a set of points to sample compute their mean and variance from the current state of the GPP</p>
<p>follows algorithm 2.1 (pg 19) of <em>Gaussian Processes for Machine Learning</em> by Rasmussen and Williams</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Returns:</th><td class="field-body">1-D numpy array, 2-D numpy array</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt id="moe.optimal_learning.EPI.src.python.models.gaussian_process.GaussianProcess.sample_from_process">
<tt class="descname">sample_from_process</tt><big>(</big><em>point_to_sample</em>, <em>random_normal=None</em>, <em>sample_variance=None</em>, <em>sample_variance_normal=None</em><big>)</big><a class="reference internal" href="_modules/moe/optimal_learning/EPI/src/python/models/gaussian_process.html#GaussianProcess.sample_from_process"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#moe.optimal_learning.EPI.src.python.models.gaussian_process.GaussianProcess.sample_from_process" title="Permalink to this definition">¶</a></dt>
<dd><p>Return a sample value from the process at a given point</p>
<p>Returns the mean at that point plus the variance multipled by a random normal variable (or one provided)</p>
</dd></dl>

<dl class="method">
<dt id="moe.optimal_learning.EPI.src.python.models.gaussian_process.GaussianProcess.update_chol_parts">
<tt class="descname">update_chol_parts</tt><big>(</big><em>include_sample_variance=True</em><big>)</big><a class="reference internal" href="_modules/moe/optimal_learning/EPI/src/python/models/gaussian_process.html#GaussianProcess.update_chol_parts"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#moe.optimal_learning.EPI.src.python.models.gaussian_process.GaussianProcess.update_chol_parts" title="Permalink to this definition">¶</a></dt>
<dd><p>Get the cholesky parts of the GP</p>
<p>See page 19 of <em>Gaussian Processes for Machine Learning</em> by Rasmussen and Williams.</p>
</dd></dl>

<dl class="method">
<dt id="moe.optimal_learning.EPI.src.python.models.gaussian_process.GaussianProcess.update_cop">
<tt class="descname">update_cop</tt><big>(</big><big>)</big><a class="reference internal" href="_modules/moe/optimal_learning/EPI/src/python/models/gaussian_process.html#GaussianProcess.update_cop"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#moe.optimal_learning.EPI.src.python.models.gaussian_process.GaussianProcess.update_cop" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="method">
<dt id="moe.optimal_learning.EPI.src.python.models.gaussian_process.GaussianProcess.update_state">
<tt class="descname">update_state</tt><big>(</big><big>)</big><a class="reference internal" href="_modules/moe/optimal_learning/EPI/src/python/models/gaussian_process.html#GaussianProcess.update_state"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#moe.optimal_learning.EPI.src.python.models.gaussian_process.GaussianProcess.update_state" title="Permalink to this definition">¶</a></dt>
<dd><p>Updates the state variables</p>
</dd></dl>

</dd></dl>

</div>
<div class="section" id="module-moe.optimal_learning.EPI.src.python.models.optimal_gaussian_process">
<span id="moe-optimal-learning-epi-src-python-models-optimal-gaussian-process-module"></span><h2>moe.optimal_learning.EPI.src.python.models.optimal_gaussian_process module<a class="headerlink" href="#module-moe.optimal_learning.EPI.src.python.models.optimal_gaussian_process" title="Permalink to this headline">¶</a></h2>
<dl class="class">
<dt id="moe.optimal_learning.EPI.src.python.models.optimal_gaussian_process.OptimalGaussianProcess">
<em class="property">class </em><tt class="descclassname">moe.optimal_learning.EPI.src.python.models.optimal_gaussian_process.</tt><tt class="descname">OptimalGaussianProcess</tt><big>(</big><em>max_number_of_threads=1</em>, <em>*args</em>, <em>**kwargs</em><big>)</big><a class="reference internal" href="_modules/moe/optimal_learning/EPI/src/python/models/optimal_gaussian_process.html#OptimalGaussianProcess"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#moe.optimal_learning.EPI.src.python.models.optimal_gaussian_process.OptimalGaussianProcess" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference internal" href="#moe.optimal_learning.EPI.src.python.models.gaussian_process.GaussianProcess" title="moe.optimal_learning.EPI.src.python.models.gaussian_process.GaussianProcess"><tt class="xref py py-class docutils literal"><span class="pre">moe.optimal_learning.EPI.src.python.models.gaussian_process.GaussianProcess</span></tt></a></p>
<p>docstring!</p>
<dl class="method">
<dt id="moe.optimal_learning.EPI.src.python.models.optimal_gaussian_process.OptimalGaussianProcess.get_1D_analytic_expected_improvement">
<tt class="descname">get_1D_analytic_expected_improvement</tt><big>(</big><em>point_to_sample</em><big>)</big><a class="reference internal" href="_modules/moe/optimal_learning/EPI/src/python/models/optimal_gaussian_process.html#OptimalGaussianProcess.get_1D_analytic_expected_improvement"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#moe.optimal_learning.EPI.src.python.models.optimal_gaussian_process.OptimalGaussianProcess.get_1D_analytic_expected_improvement" title="Permalink to this definition">¶</a></dt>
<dd><p>Calculate the expected improvement for a single point exactly using normal pdf/cdf</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Returns:</th><td class="field-body">double</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt id="moe.optimal_learning.EPI.src.python.models.optimal_gaussian_process.OptimalGaussianProcess.get_1D_analytic_grad_EI">
<tt class="descname">get_1D_analytic_grad_EI</tt><big>(</big><em>point_to_sample</em><big>)</big><a class="reference internal" href="_modules/moe/optimal_learning/EPI/src/python/models/optimal_gaussian_process.html#OptimalGaussianProcess.get_1D_analytic_grad_EI"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#moe.optimal_learning.EPI.src.python.models.optimal_gaussian_process.OptimalGaussianProcess.get_1D_analytic_grad_EI" title="Permalink to this definition">¶</a></dt>
<dd><p>Return the analytic derivative of the EI for a single sample point</p>
<p>see GiLeCa08</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Returns:</th><td class="field-body">double</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt id="moe.optimal_learning.EPI.src.python.models.optimal_gaussian_process.OptimalGaussianProcess.get_2D_analytic_expected_improvement">
<tt class="descname">get_2D_analytic_expected_improvement</tt><big>(</big><em>point_one</em>, <em>point_two</em><big>)</big><a class="reference internal" href="_modules/moe/optimal_learning/EPI/src/python/models/optimal_gaussian_process.html#OptimalGaussianProcess.get_2D_analytic_expected_improvement"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#moe.optimal_learning.EPI.src.python.models.optimal_gaussian_process.OptimalGaussianProcess.get_2D_analytic_expected_improvement" title="Permalink to this definition">¶</a></dt>
<dd><p>Calculate the expected improvement for two points exactly</p>
<p>following GiLeCa08, with some errors corrected</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Returns:</th><td class="field-body">double</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt id="moe.optimal_learning.EPI.src.python.models.optimal_gaussian_process.OptimalGaussianProcess.get_expected_grad_EI">
<tt class="descname">get_expected_grad_EI</tt><big>(</big><em>current_point</em>, <em>points_being_sampled</em>, <em>iterations=100</em><big>)</big><a class="reference internal" href="_modules/moe/optimal_learning/EPI/src/python/models/optimal_gaussian_process.html#OptimalGaussianProcess.get_expected_grad_EI"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#moe.optimal_learning.EPI.src.python.models.optimal_gaussian_process.OptimalGaussianProcess.get_expected_grad_EI" title="Permalink to this definition">¶</a></dt>
<dd><p>get the expected EI grad at [current_point, points_being_sampled] wrt current_point</p>
</dd></dl>

<dl class="method">
<dt id="moe.optimal_learning.EPI.src.python.models.optimal_gaussian_process.OptimalGaussianProcess.get_expected_improvement">
<tt class="descname">get_expected_improvement</tt><big>(</big><em>points_to_sample</em>, <em>iterations=1000</em><big>)</big><a class="reference internal" href="_modules/moe/optimal_learning/EPI/src/python/models/optimal_gaussian_process.html#OptimalGaussianProcess.get_expected_improvement"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#moe.optimal_learning.EPI.src.python.models.optimal_gaussian_process.OptimalGaussianProcess.get_expected_improvement" title="Permalink to this definition">¶</a></dt>
<dd><p>Calculate the expected improvement at <em>points_to_sample</em> over a certain number of MC <em>iterations</em> in a <em>domain</em></p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Returns:</th><td class="field-body">double</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt id="moe.optimal_learning.EPI.src.python.models.optimal_gaussian_process.OptimalGaussianProcess.get_multistart_best">
<tt class="descname">get_multistart_best</tt><big>(</big><em>random_restarts=5</em>, <em>points_being_sampled=</em><span class="optional">[</span><span class="optional">]</span><big>)</big><a class="reference internal" href="_modules/moe/optimal_learning/EPI/src/python/models/optimal_gaussian_process.html#OptimalGaussianProcess.get_multistart_best"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#moe.optimal_learning.EPI.src.python.models.optimal_gaussian_process.OptimalGaussianProcess.get_multistart_best" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="method">
<dt id="moe.optimal_learning.EPI.src.python.models.optimal_gaussian_process.OptimalGaussianProcess.get_next_step">
<tt class="descname">get_next_step</tt><big>(</big><em>starting_point</em>, <em>points_being_sampled</em>, <em>domain=None</em>, <em>gamma=0.8</em>, <em>iterations=1000</em>, <em>max_N=400</em><big>)</big><a class="reference internal" href="_modules/moe/optimal_learning/EPI/src/python/models/optimal_gaussian_process.html#OptimalGaussianProcess.get_next_step"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#moe.optimal_learning.EPI.src.python.models.optimal_gaussian_process.OptimalGaussianProcess.get_next_step" title="Permalink to this definition">¶</a></dt>
<dd><p>get the next step using polyak-ruppert</p>
</dd></dl>

<dl class="method">
<dt id="moe.optimal_learning.EPI.src.python.models.optimal_gaussian_process.OptimalGaussianProcess.get_next_step_multistart">
<tt class="descname">get_next_step_multistart</tt><big>(</big><em>starting_points</em>, <em>points_being_sampled</em>, <em>gamma=0.9</em>, <em>iterations=1000</em>, <em>max_N=100</em><big>)</big><a class="reference internal" href="_modules/moe/optimal_learning/EPI/src/python/models/optimal_gaussian_process.html#OptimalGaussianProcess.get_next_step_multistart"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#moe.optimal_learning.EPI.src.python.models.optimal_gaussian_process.OptimalGaussianProcess.get_next_step_multistart" title="Permalink to this definition">¶</a></dt>
<dd><p>get next step using multistart polyak-ruppert</p>
</dd></dl>

</dd></dl>

</div>
<div class="section" id="module-moe.optimal_learning.EPI.src.python.models.optimal_gaussian_process_linked_cpp">
<span id="moe-optimal-learning-epi-src-python-models-optimal-gaussian-process-linked-cpp-module"></span><h2>moe.optimal_learning.EPI.src.python.models.optimal_gaussian_process_linked_cpp module<a class="headerlink" href="#module-moe.optimal_learning.EPI.src.python.models.optimal_gaussian_process_linked_cpp" title="Permalink to this headline">¶</a></h2>
<dl class="class">
<dt id="moe.optimal_learning.EPI.src.python.models.optimal_gaussian_process_linked_cpp.OptimalGaussianProcessLinkedCpp">
<em class="property">class </em><tt class="descclassname">moe.optimal_learning.EPI.src.python.models.optimal_gaussian_process_linked_cpp.</tt><tt class="descname">OptimalGaussianProcessLinkedCpp</tt><big>(</big><em>max_num_threads=1</em>, <em>*args</em>, <em>**kwargs</em><big>)</big><a class="reference internal" href="_modules/moe/optimal_learning/EPI/src/python/models/optimal_gaussian_process_linked_cpp.html#OptimalGaussianProcessLinkedCpp"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#moe.optimal_learning.EPI.src.python.models.optimal_gaussian_process_linked_cpp.OptimalGaussianProcessLinkedCpp" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference internal" href="#moe.optimal_learning.EPI.src.python.models.optimal_gaussian_process.OptimalGaussianProcess" title="moe.optimal_learning.EPI.src.python.models.optimal_gaussian_process.OptimalGaussianProcess"><tt class="xref py py-class docutils literal"><span class="pre">moe.optimal_learning.EPI.src.python.models.optimal_gaussian_process.OptimalGaussianProcess</span></tt></a></p>
<p>Overrides methods in OptimalGaussianProcess with calls to C++ code in src/cpp/GPP_python.cpp via boost</p>
<dl class="method">
<dt id="moe.optimal_learning.EPI.src.python.models.optimal_gaussian_process_linked_cpp.OptimalGaussianProcessLinkedCpp.cholesky_decomp_and_grad">
<tt class="descname">cholesky_decomp_and_grad</tt><big>(</big><em>points_to_sample</em>, <em>var_of_grad=0</em><big>)</big><a class="reference internal" href="_modules/moe/optimal_learning/EPI/src/python/models/optimal_gaussian_process_linked_cpp.html#OptimalGaussianProcessLinkedCpp.cholesky_decomp_and_grad"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#moe.optimal_learning.EPI.src.python.models.optimal_gaussian_process_linked_cpp.OptimalGaussianProcessLinkedCpp.cholesky_decomp_and_grad" title="Permalink to this definition">¶</a></dt>
<dd><p>Calls into get_chol_var and get_grad_var in src/cpp/GPP_python.cpp</p>
</dd></dl>

<dl class="method">
<dt id="moe.optimal_learning.EPI.src.python.models.optimal_gaussian_process_linked_cpp.OptimalGaussianProcessLinkedCpp.compute_expected_improvement">
<tt class="descname">compute_expected_improvement</tt><big>(</big><em>points_to_sample</em>, <em>force_monte_carlo=False</em>, <em>mc_iterations=1000</em><big>)</big><a class="reference internal" href="_modules/moe/optimal_learning/EPI/src/python/models/optimal_gaussian_process_linked_cpp.html#OptimalGaussianProcessLinkedCpp.compute_expected_improvement"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#moe.optimal_learning.EPI.src.python.models.optimal_gaussian_process_linked_cpp.OptimalGaussianProcessLinkedCpp.compute_expected_improvement" title="Permalink to this definition">¶</a></dt>
<dd><p>Compute expected improvement. Calls into src/cpp/GPP_python.cpp</p>
<p>Automatically selects analytic evaluators when they are available (for performance/accuracy).
Set &#8220;force_monte_carlo&#8221; to True to force monte-carlo evaluation even if analytic is available.
(This is probably only useful for testing.)</p>
</dd></dl>

<dl class="method">
<dt id="moe.optimal_learning.EPI.src.python.models.optimal_gaussian_process_linked_cpp.OptimalGaussianProcessLinkedCpp.compute_grad_expected_improvement">
<tt class="descname">compute_grad_expected_improvement</tt><big>(</big><em>points_to_sample</em>, <em>force_monte_carlo=False</em>, <em>mc_iterations=1000</em><big>)</big><a class="reference internal" href="_modules/moe/optimal_learning/EPI/src/python/models/optimal_gaussian_process_linked_cpp.html#OptimalGaussianProcessLinkedCpp.compute_grad_expected_improvement"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#moe.optimal_learning.EPI.src.python.models.optimal_gaussian_process_linked_cpp.OptimalGaussianProcessLinkedCpp.compute_grad_expected_improvement" title="Permalink to this definition">¶</a></dt>
<dd><p>Compute spatial gradient of expected improvement. Calls into src/cpp/GPP_python.cpp</p>
<p>Automatically selects analytic evaluators when they are available (for performance/accuracy).
Set &#8220;force_monte_carlo&#8221; to True to force monte-carlo evaluation even if analytic is available.
(This is probably only useful for testing.)</p>
</dd></dl>

<dl class="method">
<dt id="moe.optimal_learning.EPI.src.python.models.optimal_gaussian_process_linked_cpp.OptimalGaussianProcessLinkedCpp.compute_hyperparam_grad_log_likelihood">
<tt class="descname">compute_hyperparam_grad_log_likelihood</tt><big>(</big><em>objective_type=moe.build.GPP.LogLikelihoodTypes.log_marginal_likelihood</em><big>)</big><a class="reference internal" href="_modules/moe/optimal_learning/EPI/src/python/models/optimal_gaussian_process_linked_cpp.html#OptimalGaussianProcessLinkedCpp.compute_hyperparam_grad_log_likelihood"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#moe.optimal_learning.EPI.src.python.models.optimal_gaussian_process_linked_cpp.OptimalGaussianProcessLinkedCpp.compute_hyperparam_grad_log_likelihood" title="Permalink to this definition">¶</a></dt>
<dd><p>Calls into compute_hyperparam_grad_log_likelihood in EPI/src/cpp/GPP_python.cpp to compute
the gradient of the requested log_likelihood measure (e.g., log marginal or leave one out) wrt the hyperparameters</p>
</dd></dl>

<dl class="method">
<dt id="moe.optimal_learning.EPI.src.python.models.optimal_gaussian_process_linked_cpp.OptimalGaussianProcessLinkedCpp.compute_log_likelihood">
<tt class="descname">compute_log_likelihood</tt><big>(</big><em>objective_type=moe.build.GPP.LogLikelihoodTypes.log_marginal_likelihood</em><big>)</big><a class="reference internal" href="_modules/moe/optimal_learning/EPI/src/python/models/optimal_gaussian_process_linked_cpp.html#OptimalGaussianProcessLinkedCpp.compute_log_likelihood"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#moe.optimal_learning.EPI.src.python.models.optimal_gaussian_process_linked_cpp.OptimalGaussianProcessLinkedCpp.compute_log_likelihood" title="Permalink to this definition">¶</a></dt>
<dd><p>Calls into compute_log_likelihood in EPI/src/cpp/GPP_python.cpp to compute
the requested log_likelihood measure (e.g., log marginal or leave one out)</p>
</dd></dl>

<dl class="method">
<dt id="moe.optimal_learning.EPI.src.python.models.optimal_gaussian_process_linked_cpp.OptimalGaussianProcessLinkedCpp.constant_liar_expected_improvement_optimization">
<tt class="descname">constant_liar_expected_improvement_optimization</tt><big>(</big><em>ei_optimization_parameters</em>, <em>num_samples_to_generate</em>, <em>lie_value</em>, <em>lie_noise_variance=0.0</em>, <em>domain=None</em>, <em>status=None</em><big>)</big><a class="reference internal" href="_modules/moe/optimal_learning/EPI/src/python/models/optimal_gaussian_process_linked_cpp.html#OptimalGaussianProcessLinkedCpp.constant_liar_expected_improvement_optimization"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#moe.optimal_learning.EPI.src.python.models.optimal_gaussian_process_linked_cpp.OptimalGaussianProcessLinkedCpp.constant_liar_expected_improvement_optimization" title="Permalink to this definition">¶</a></dt>
<dd><p>Calls into heuristic_expected_improvement_optimization_wrapper in EPI/src/cpp/GPP_python.cpp (solving q,0-EI)
with the ConstantLiarEstimationPolicy.</p>
<p>double lie_value: the &#8220;constant lie&#8221; that this estimator should return
double lie_noise_variance: the noise_variance to associate to the lie_value (MUST be &gt;= 0.0)</p>
</dd></dl>

<dl class="method">
<dt id="moe.optimal_learning.EPI.src.python.models.optimal_gaussian_process_linked_cpp.OptimalGaussianProcessLinkedCpp.evaluate_expected_improvement_at_point_list">
<tt class="descname">evaluate_expected_improvement_at_point_list</tt><big>(</big><em>points_to_evaluate</em>, <em>points_being_sampled=array(</em>, <span class="optional">[</span><span class="optional">]</span><em>dtype=float64)</em>, <em>mc_iterations=1000</em>, <em>status=None</em><big>)</big><a class="reference internal" href="_modules/moe/optimal_learning/EPI/src/python/models/optimal_gaussian_process_linked_cpp.html#OptimalGaussianProcessLinkedCpp.evaluate_expected_improvement_at_point_list"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#moe.optimal_learning.EPI.src.python.models.optimal_gaussian_process_linked_cpp.OptimalGaussianProcessLinkedCpp.evaluate_expected_improvement_at_point_list" title="Permalink to this definition">¶</a></dt>
<dd><p>Calls into evaluate_EI_at_point_list_wrapper() in src/cpp/GPP_python.cpp</p>
</dd></dl>

<dl class="method">
<dt id="moe.optimal_learning.EPI.src.python.models.optimal_gaussian_process_linked_cpp.OptimalGaussianProcessLinkedCpp.evaluate_log_likelihood_at_hyperparameter_list">
<tt class="descname">evaluate_log_likelihood_at_hyperparameter_list</tt><big>(</big><em>hyperparameters_to_evaluate</em>, <em>objective_type=moe.build.GPP.LogLikelihoodTypes.log_marginal_likelihood</em><big>)</big><a class="reference internal" href="_modules/moe/optimal_learning/EPI/src/python/models/optimal_gaussian_process_linked_cpp.html#OptimalGaussianProcessLinkedCpp.evaluate_log_likelihood_at_hyperparameter_list"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#moe.optimal_learning.EPI.src.python.models.optimal_gaussian_process_linked_cpp.OptimalGaussianProcessLinkedCpp.evaluate_log_likelihood_at_hyperparameter_list" title="Permalink to this definition">¶</a></dt>
<dd><p>Calls into evaluate_log_likelihood_at_hyperparameter_list_wrapper() in src/cpp/GPP_python.cpp</p>
</dd></dl>

<dl class="method">
<dt id="moe.optimal_learning.EPI.src.python.models.optimal_gaussian_process_linked_cpp.OptimalGaussianProcessLinkedCpp.get_1D_analytic_expected_improvement">
<tt class="descname">get_1D_analytic_expected_improvement</tt><big>(</big><em>point_to_sample</em><big>)</big><a class="reference internal" href="_modules/moe/optimal_learning/EPI/src/python/models/optimal_gaussian_process_linked_cpp.html#OptimalGaussianProcessLinkedCpp.get_1D_analytic_expected_improvement"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#moe.optimal_learning.EPI.src.python.models.optimal_gaussian_process_linked_cpp.OptimalGaussianProcessLinkedCpp.get_1D_analytic_expected_improvement" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="method">
<dt id="moe.optimal_learning.EPI.src.python.models.optimal_gaussian_process_linked_cpp.OptimalGaussianProcessLinkedCpp.get_1D_analytic_grad_EI">
<tt class="descname">get_1D_analytic_grad_EI</tt><big>(</big><em>point_to_sample</em><big>)</big><a class="reference internal" href="_modules/moe/optimal_learning/EPI/src/python/models/optimal_gaussian_process_linked_cpp.html#OptimalGaussianProcessLinkedCpp.get_1D_analytic_grad_EI"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#moe.optimal_learning.EPI.src.python.models.optimal_gaussian_process_linked_cpp.OptimalGaussianProcessLinkedCpp.get_1D_analytic_grad_EI" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="method">
<dt id="moe.optimal_learning.EPI.src.python.models.optimal_gaussian_process_linked_cpp.OptimalGaussianProcessLinkedCpp.get_expected_improvement">
<tt class="descname">get_expected_improvement</tt><big>(</big><em>points_to_sample</em>, <em>mc_iterations=1000</em><big>)</big><a class="reference internal" href="_modules/moe/optimal_learning/EPI/src/python/models/optimal_gaussian_process_linked_cpp.html#OptimalGaussianProcessLinkedCpp.get_expected_improvement"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#moe.optimal_learning.EPI.src.python.models.optimal_gaussian_process_linked_cpp.OptimalGaussianProcessLinkedCpp.get_expected_improvement" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="method">
<dt id="moe.optimal_learning.EPI.src.python.models.optimal_gaussian_process_linked_cpp.OptimalGaussianProcessLinkedCpp.get_grad_expected_improvement">
<tt class="descname">get_grad_expected_improvement</tt><big>(</big><em>points_to_sample</em>, <em>mc_iterations=1000</em><big>)</big><a class="reference internal" href="_modules/moe/optimal_learning/EPI/src/python/models/optimal_gaussian_process_linked_cpp.html#OptimalGaussianProcessLinkedCpp.get_grad_expected_improvement"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#moe.optimal_learning.EPI.src.python.models.optimal_gaussian_process_linked_cpp.OptimalGaussianProcessLinkedCpp.get_grad_expected_improvement" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="method">
<dt id="moe.optimal_learning.EPI.src.python.models.optimal_gaussian_process_linked_cpp.OptimalGaussianProcessLinkedCpp.get_grad_mu">
<tt class="descname">get_grad_mu</tt><big>(</big><em>points_to_sample</em><big>)</big><a class="reference internal" href="_modules/moe/optimal_learning/EPI/src/python/models/optimal_gaussian_process_linked_cpp.html#OptimalGaussianProcessLinkedCpp.get_grad_mu"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#moe.optimal_learning.EPI.src.python.models.optimal_gaussian_process_linked_cpp.OptimalGaussianProcessLinkedCpp.get_grad_mu" title="Permalink to this definition">¶</a></dt>
<dd><p>Calls into get_grad_mean_wrapper in src/cpp/GPP_python.cpp</p>
</dd></dl>

<dl class="method">
<dt id="moe.optimal_learning.EPI.src.python.models.optimal_gaussian_process_linked_cpp.OptimalGaussianProcessLinkedCpp.get_hyperparam_grad_log_marginal_likelihood">
<tt class="descname">get_hyperparam_grad_log_marginal_likelihood</tt><big>(</big><big>)</big><a class="reference internal" href="_modules/moe/optimal_learning/EPI/src/python/models/optimal_gaussian_process_linked_cpp.html#OptimalGaussianProcessLinkedCpp.get_hyperparam_grad_log_marginal_likelihood"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#moe.optimal_learning.EPI.src.python.models.optimal_gaussian_process_linked_cpp.OptimalGaussianProcessLinkedCpp.get_hyperparam_grad_log_marginal_likelihood" title="Permalink to this definition">¶</a></dt>
<dd><p>Wrapper for compute_hyperparam_grad_log_likelihood</p>
</dd></dl>

<dl class="method">
<dt id="moe.optimal_learning.EPI.src.python.models.optimal_gaussian_process_linked_cpp.OptimalGaussianProcessLinkedCpp.get_log_marginal_likelihood">
<tt class="descname">get_log_marginal_likelihood</tt><big>(</big><big>)</big><a class="reference internal" href="_modules/moe/optimal_learning/EPI/src/python/models/optimal_gaussian_process_linked_cpp.html#OptimalGaussianProcessLinkedCpp.get_log_marginal_likelihood"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#moe.optimal_learning.EPI.src.python.models.optimal_gaussian_process_linked_cpp.OptimalGaussianProcessLinkedCpp.get_log_marginal_likelihood" title="Permalink to this definition">¶</a></dt>
<dd><p>Wrapper for compute_log_likelihood</p>
</dd></dl>

<dl class="method">
<dt id="moe.optimal_learning.EPI.src.python.models.optimal_gaussian_process_linked_cpp.OptimalGaussianProcessLinkedCpp.get_mean_and_var_of_points">
<tt class="descname">get_mean_and_var_of_points</tt><big>(</big><em>points_to_sample</em><big>)</big><a class="reference internal" href="_modules/moe/optimal_learning/EPI/src/python/models/optimal_gaussian_process_linked_cpp.html#OptimalGaussianProcessLinkedCpp.get_mean_and_var_of_points"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#moe.optimal_learning.EPI.src.python.models.optimal_gaussian_process_linked_cpp.OptimalGaussianProcessLinkedCpp.get_mean_and_var_of_points" title="Permalink to this definition">¶</a></dt>
<dd><p>Calls into get_mean and get_var wrapper in src/cpp/GPP_python.cpp</p>
</dd></dl>

<dl class="method">
<dt id="moe.optimal_learning.EPI.src.python.models.optimal_gaussian_process_linked_cpp.OptimalGaussianProcessLinkedCpp.get_multistart_best">
<tt class="descname">get_multistart_best</tt><big>(</big><em>starting_points=None</em>, <em>points_being_sampled=array(</em>, <span class="optional">[</span><span class="optional">]</span><em>dtype=float64)</em>, <em>gamma=0.9</em>, <em>gd_iterations=1000</em>, <em>mc_iterations=1000</em>, <em>num_multistarts=5</em>, <em>max_num_restarts=3</em>, <em>max_relative_change=1.0</em>, <em>tolerance=1e-07</em>, <em>status=None</em><big>)</big><a class="reference internal" href="_modules/moe/optimal_learning/EPI/src/python/models/optimal_gaussian_process_linked_cpp.html#OptimalGaussianProcessLinkedCpp.get_multistart_best"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#moe.optimal_learning.EPI.src.python.models.optimal_gaussian_process_linked_cpp.OptimalGaussianProcessLinkedCpp.get_multistart_best" title="Permalink to this definition">¶</a></dt>
<dd><p>Wrapper for multistart_expected_improvement_optimization</p>
</dd></dl>

<dl class="method">
<dt id="moe.optimal_learning.EPI.src.python.models.optimal_gaussian_process_linked_cpp.OptimalGaussianProcessLinkedCpp.kriging_believer_expected_improvement_optimization">
<tt class="descname">kriging_believer_expected_improvement_optimization</tt><big>(</big><em>ei_optimization_parameters</em>, <em>num_samples_to_generate</em>, <em>std_deviation_coef=0.0</em>, <em>kriging_noise_variance=0.0</em>, <em>domain=None</em>, <em>status=None</em><big>)</big><a class="reference internal" href="_modules/moe/optimal_learning/EPI/src/python/models/optimal_gaussian_process_linked_cpp.html#OptimalGaussianProcessLinkedCpp.kriging_believer_expected_improvement_optimization"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#moe.optimal_learning.EPI.src.python.models.optimal_gaussian_process_linked_cpp.OptimalGaussianProcessLinkedCpp.kriging_believer_expected_improvement_optimization" title="Permalink to this definition">¶</a></dt>
<dd><p>Calls into heuristic_expected_improvement_optimization_wrapper in EPI/src/cpp/GPP_python.cpp (solving q,0-EI)
with the KrigingBelieverEstimationPolicy.</p>
<p>double std_deviation_coef: the relative amount of bias (in units of GP std deviation) to introduce into the GP mean
double kriging_noise_variance: the noise_variance to associate to each function value estimate (MUST be &gt;= 0.0)</p>
</dd></dl>

<dl class="method">
<dt id="moe.optimal_learning.EPI.src.python.models.optimal_gaussian_process_linked_cpp.OptimalGaussianProcessLinkedCpp.multistart_expected_improvement_optimization">
<tt class="descname">multistart_expected_improvement_optimization</tt><big>(</big><em>ei_optimization_parameters</em>, <em>num_samples_to_generate</em>, <em>domain=None</em>, <em>points_being_sampled=array(</em>, <span class="optional">[</span><span class="optional">]</span><em>dtype=float64)</em>, <em>mc_iterations=1000</em>, <em>status=None</em><big>)</big><a class="reference internal" href="_modules/moe/optimal_learning/EPI/src/python/models/optimal_gaussian_process_linked_cpp.html#OptimalGaussianProcessLinkedCpp.multistart_expected_improvement_optimization"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#moe.optimal_learning.EPI.src.python.models.optimal_gaussian_process_linked_cpp.OptimalGaussianProcessLinkedCpp.multistart_expected_improvement_optimization" title="Permalink to this definition">¶</a></dt>
<dd><p>Calls into multistart_expected_improvement_optimization_wrapper in EPI/src/cpp/GPP_python.cpp (solving q,p-EI)</p>
</dd></dl>

<dl class="method">
<dt id="moe.optimal_learning.EPI.src.python.models.optimal_gaussian_process_linked_cpp.OptimalGaussianProcessLinkedCpp.multistart_hyperparameter_optimization">
<tt class="descname">multistart_hyperparameter_optimization</tt><big>(</big><em>hyperparameter_optimization_parameters</em>, <em>hyperparameter_domain=None</em>, <em>status=None</em><big>)</big><a class="reference internal" href="_modules/moe/optimal_learning/EPI/src/python/models/optimal_gaussian_process_linked_cpp.html#OptimalGaussianProcessLinkedCpp.multistart_hyperparameter_optimization"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#moe.optimal_learning.EPI.src.python.models.optimal_gaussian_process_linked_cpp.OptimalGaussianProcessLinkedCpp.multistart_hyperparameter_optimization" title="Permalink to this definition">¶</a></dt>
<dd><p>Optimizes hyperparameters based on maximizing the log likelihood-like measures using a multistart optimizer:
log_marginal_likelihood     : log marginal likelihood (that the data comes from the model, p(y | X,     heta).
leave_one_out_log_likelihood: leave-one-out log pseudo-likelihood, which evaluates the ability of the
model to predict each member of its training set:
sum_{i=1}^n log p(y_i | X_{-i}, y_{-i},        heta), where X_{-i}, y_{-i} denotes the parent set with i-th member removed</p>
<p>Optimizers are: null (&#8216;dumb&#8217; search), gradient descent, newton
&#8216;dumb&#8217; search means this will just evaluate the objective log likelihood measure at num_multistarts &#8216;points&#8217;
(hyperparameters) in the domain, uniformly sampled using latin hypercube sampling.</p>
<p>See gpp_python.cpp for C++ enum declarations laying out the options for objective and optimizer types.</p>
</dd></dl>

</dd></dl>

</div>
<div class="section" id="moe-optimal-learning-epi-src-python-models-plottable-optimal-gaussian-process-module">
<h2>moe.optimal_learning.EPI.src.python.models.plottable_optimal_gaussian_process module<a class="headerlink" href="#moe-optimal-learning-epi-src-python-models-plottable-optimal-gaussian-process-module" title="Permalink to this headline">¶</a></h2>
</div>
<div class="section" id="module-moe.optimal_learning.EPI.src.python.models">
<span id="module-contents"></span><h2>Module contents<a class="headerlink" href="#module-moe.optimal_learning.EPI.src.python.models" title="Permalink to this headline">¶</a></h2>
</div>
</div>


          </div>
          <footer>
  
    <div class="rst-footer-buttons" role="navigation" aria-label="footer navigation">
      
        <a href="moe.tests.html" class="btn btn-neutral float-right" title="moe.tests package"/>Next <span class="fa fa-arrow-circle-right"></span></a>
      
      
        <a href="moe.optimal_learning.EPI.src.python.lib.html" class="btn btn-neutral" title="moe.optimal_learning.EPI.src.python.lib package"><span class="fa fa-arrow-circle-left"></span> Previous</a>
      
    </div>
  

  <hr/>

  <div role="contentinfo">
    <p>
        &copy; Copyright 2014, Yelp and Cornell Collaboration.
    </p>
  </div>

  <a href="https://github.com/snide/sphinx_rtd_theme">Sphinx theme</a> provided by <a href="https://readthedocs.org">Read the Docs</a>
</footer>
        </div>
      </div>

    </section>

  </div>
  


  

    <script type="text/javascript">
        var DOCUMENTATION_OPTIONS = {
            URL_ROOT:'./',
            VERSION:'0.1.0',
            COLLAPSE_INDEX:false,
            FILE_SUFFIX:'.html',
            HAS_SOURCE:  true
        };
    </script>
      <script type="text/javascript" src="_static/jquery.js"></script>
      <script type="text/javascript" src="_static/underscore.js"></script>
      <script type="text/javascript" src="_static/doctools.js"></script>
      <script type="text/javascript" src="http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>

  

  
  
    <script type="text/javascript" src="_static/js/theme.js"></script>
  

  
  
  <script type="text/javascript">
      jQuery(function () {
          SphinxRtdTheme.StickyNav.enable();
      });
  </script>
   

</body>
</html>