

<!DOCTYPE html>
<!--[if IE 8]><html class="no-js lt-ie9" lang="en" > <![endif]-->
<!--[if gt IE 8]><!--> <html class="no-js" lang="en" > <!--<![endif]-->
<head>
  <meta charset="utf-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  
  <title>gpp_math_test &mdash; MOE 0.1.0 documentation</title>
  

  
  
    <link rel="shortcut icon" href="_static/favicon.ico"/>
  

  
  <link href='https://fonts.googleapis.com/css?family=Lato:400,700|Roboto+Slab:400,700|Inconsolata:400,700' rel='stylesheet' type='text/css'>

  
  
    

  

  
  
    <link rel="stylesheet" href="_static/css/theme.css" type="text/css" />
  

  
    <link rel="stylesheet" href="_static/breathe.css" type="text/css" />
  
    <link rel="top" title="MOE 0.1.0 documentation" href="index.html"/>
        <link rel="up" title="C++ Files" href="cpp_tree.html"/>
        <link rel="next" title="gpp_python_expected_improvement" href="gpp_python_expected_improvement.html"/>
        <link rel="prev" title="gpp_test_utils_test" href="gpp_test_utils_test.html"/> 

  
  <script src="https://cdnjs.cloudflare.com/ajax/libs/modernizr/2.6.2/modernizr.min.js"></script>

</head>

<body class="wy-body-for-nav" role="document">

  <div class="wy-grid-for-nav">

    
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-nav-search">
        <a href="index.html" class="fa fa-home"> MOE</a>
        <div role="search">
  <form id ="rtd-search-form" class="wy-form" action="search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>
      </div>

      <div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="main navigation">
        
        
            <ul>
<li class="toctree-l1"><a class="reference internal" href="why_moe.html">Why Do We Need MOE?</a><ul>
<li class="toctree-l2"><a class="reference internal" href="why_moe.html#other-methods">Other Methods</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="install.html">Install</a><ul>
<li class="toctree-l2"><a class="reference internal" href="install.html#install-in-docker">Install in docker</a></li>
<li class="toctree-l2"><a class="reference internal" href="install.html#install-from-source">Install from source</a></li>
<li class="toctree-l2"><a class="reference internal" href="install.html#osx-tips">OSX Tips</a></li>
<li class="toctree-l2"><a class="reference internal" href="install.html#building-boost">Building Boost</a></li>
<li class="toctree-l2"><a class="reference internal" href="install.html#linux-tips">Linux Tips</a></li>
<li class="toctree-l2"><a class="reference internal" href="install.html#cmake-tips">CMake Tips</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="moe_math.html">How does MOE work?</a><ul>
<li class="toctree-l2"><a class="reference internal" href="moe_math.html#build-a-gaussian-process-gp-with-the-historical-data">Build a Gaussian Process (GP) with the historical data</a></li>
<li class="toctree-l2"><a class="reference internal" href="moe_math.html#optimize-the-hyperparameters-of-the-gaussian-process">Optimize the hyperparameters of the Gaussian Process</a></li>
<li class="toctree-l2"><a class="reference internal" href="moe_math.html#find-the-point-s-of-highest-expected-improvement-ei">Find the point(s) of highest Expected Improvement (EI)</a></li>
<li class="toctree-l2"><a class="reference internal" href="moe_math.html#return-the-point-s-to-sample-then-repeat">Return the point(s) to sample, then repeat</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="demo_tutorial.html">Demo Tutorial</a><ul>
<li class="toctree-l2"><a class="reference internal" href="demo_tutorial.html#the-interactive-demo">The Interactive Demo</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="pretty_endpoints.html">Pretty Endpoints</a></li>
<li class="toctree-l1"><a class="reference internal" href="objective_functions.html">Objective Functions</a><ul>
<li class="toctree-l2"><a class="reference internal" href="objective_functions.html#what-is-an-objective-function">What is an objective function?</a></li>
<li class="toctree-l2"><a class="reference internal" href="objective_functions.html#properties-of-an-objective-function">Properties of an objective function</a></li>
<li class="toctree-l2"><a class="reference internal" href="objective_functions.html#parameters">Parameters</a></li>
<li class="toctree-l2"><a class="reference internal" href="objective_functions.html#id1"><span class="math">\(\Phi\)</span> Objective Functions</a></li>
<li class="toctree-l2"><a class="reference internal" href="objective_functions.html#example-of-objective-functions">Example of Objective Functions</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="examples.html">Examples</a><ul>
<li class="toctree-l2"><a class="reference internal" href="examples.html#minimizing-an-arbitrary-function">Minimizing an arbitrary function</a></li>
<li class="toctree-l2"><a class="reference internal" href="examples.html#gaussian-process-regression-given-historical-data">Gaussian Process regression given historical data</a></li>
<li class="toctree-l2"><a class="reference internal" href="examples.html#hyperparameter-optimization-of-a-gaussian-process">Hyperparameter optimization of a Gaussian Process</a></li>
<li class="toctree-l2"><a class="reference internal" href="examples.html#all-above-examples-combined">All above examples combined</a></li>
<li class="toctree-l2"><a class="reference internal" href="examples.html#setting-thresholds-for-advertising-units">Setting thresholds for advertising units</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="contributing.html">Contributing</a><ul>
<li class="toctree-l2"><a class="reference internal" href="contributing.html#making-a-pull-request">Making a pull request</a></li>
<li class="toctree-l2"><a class="reference internal" href="contributing.html#documentation">Documentation</a></li>
<li class="toctree-l2"><a class="reference internal" href="contributing.html#testing">Testing</a></li>
<li class="toctree-l2"><a class="reference internal" href="contributing.html#style">Style</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="faq.html">Frequently Asked Questions</a><ul>
<li class="toctree-l2"><a class="reference internal" href="faq.html#what-license-is-moe-released-under">What license is MOE released under?</a></li>
<li class="toctree-l2"><a class="reference internal" href="faq.html#when-should-i-use-moe">When should I use MOE?</a></li>
<li class="toctree-l2"><a class="reference internal" href="faq.html#what-is-the-time-complexity-of-moe">What is the time complexity of MOE?</a></li>
<li class="toctree-l2"><a class="reference internal" href="faq.html#how-do-i-cite-moe">How do I cite MOE?</a></li>
<li class="toctree-l2"><a class="reference internal" href="faq.html#why-does-moe-take-so-long-to-return-the-next-points-to-sample-for-some-inputs">Why does MOE take so long to return the next points to sample for some inputs?</a></li>
<li class="toctree-l2"><a class="reference internal" href="faq.html#how-do-i-bootstrap-moe-what-initial-data-does-it-need">How do I bootstrap MOE? What initial data does it need?</a></li>
<li class="toctree-l2"><a class="reference internal" href="faq.html#how-many-function-evaluations-do-i-need-before-moe-is-done">How many function evaluations do I need before MOE is &#8220;done&#8221;?</a></li>
<li class="toctree-l2"><a class="reference internal" href="faq.html#how-many-function-evaluations-do-i-perform-before-i-update-the-hyperparameters-of-the-gp">How many function evaluations do I perform before I update the hyperparameters of the GP?</a></li>
<li class="toctree-l2"><a class="reference internal" href="faq.html#will-you-accept-my-pull-request">Will you accept my pull request?</a></li>
</ul>
</li>
</ul>
<ul>
<li class="toctree-l1"><a class="reference internal" href="moe.html">moe package</a><ul>
<li class="toctree-l2"><a class="reference internal" href="moe.html#subpackages">Subpackages</a></li>
<li class="toctree-l2"><a class="reference internal" href="moe.html#submodules">Submodules</a></li>
<li class="toctree-l2"><a class="reference internal" href="moe.html#module-moe.resources">moe.resources module</a></li>
<li class="toctree-l2"><a class="reference internal" href="moe.html#module-moe">Module contents</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="moe_examples.html">moe_examples package</a><ul>
<li class="toctree-l2"><a class="reference internal" href="moe_examples.html#subpackages">Subpackages</a></li>
<li class="toctree-l2"><a class="reference internal" href="moe_examples.html#submodules">Submodules</a></li>
<li class="toctree-l2"><a class="reference internal" href="moe_examples.html#module-moe_examples.combined_example">moe_examples.combined_example module</a></li>
<li class="toctree-l2"><a class="reference internal" href="moe_examples.html#module-moe_examples.hyper_opt_of_gp_from_historical_data">moe_examples.hyper_opt_of_gp_from_historical_data module</a></li>
<li class="toctree-l2"><a class="reference internal" href="moe_examples.html#module-moe_examples.mean_and_var_of_gp_from_historic_data">moe_examples.mean_and_var_of_gp_from_historic_data module</a></li>
<li class="toctree-l2"><a class="reference internal" href="moe_examples.html#module-moe_examples.next_point_via_simple_endpoint">moe_examples.next_point_via_simple_endpoint module</a></li>
<li class="toctree-l2"><a class="reference internal" href="moe_examples.html#module-moe_examples">Module contents</a></li>
</ul>
</li>
</ul>
<ul class="current">
<li class="toctree-l1 current"><a class="reference internal" href="cpp_tree.html">C++ Files</a><ul class="current">
<li class="toctree-l2"><a class="reference internal" href="gpp_optimization_test.html">gpp_optimization_test</a></li>
<li class="toctree-l2"><a class="reference internal" href="gpp_domain_test.html">gpp_domain_test</a></li>
<li class="toctree-l2"><a class="reference internal" href="gpp_exception.html">gpp_exception</a></li>
<li class="toctree-l2"><a class="reference internal" href="gpp_geometry.html">gpp_geometry</a></li>
<li class="toctree-l2"><a class="reference internal" href="gpp_heuristic_expected_improvement_optimization.html">gpp_heuristic_expected_improvement_optimization</a></li>
<li class="toctree-l2"><a class="reference internal" href="gpp_linear_algebra-inl.html">gpp_linear_algebra-inl</a></li>
<li class="toctree-l2"><a class="reference internal" href="gpp_test_utils.html">gpp_test_utils</a></li>
<li class="toctree-l2"><a class="reference internal" href="gpp_logging.html">gpp_logging</a></li>
<li class="toctree-l2"><a class="reference internal" href="gpp_covariance.html">gpp_covariance</a></li>
<li class="toctree-l2"><a class="reference internal" href="gpp_python_test.html">gpp_python_test</a></li>
<li class="toctree-l2"><a class="reference internal" href="gpp_domain.html">gpp_domain</a></li>
<li class="toctree-l2"><a class="reference internal" href="gpp_python_common.html">gpp_python_common</a></li>
<li class="toctree-l2"><a class="reference internal" href="gpp_hyperparameter_optimization_demo.html">gpp_hyperparameter_optimization_demo</a></li>
<li class="toctree-l2"><a class="reference internal" href="gpp_test_utils_test.html">gpp_test_utils_test</a></li>
<li class="toctree-l2 current"><a class="current reference internal" href="">gpp_math_test</a></li>
<li class="toctree-l2"><a class="reference internal" href="gpp_python_expected_improvement.html">gpp_python_expected_improvement</a></li>
<li class="toctree-l2"><a class="reference internal" href="gpp_python_model_selection.html">gpp_python_model_selection</a></li>
<li class="toctree-l2"><a class="reference internal" href="gpp_math.html">gpp_math</a></li>
<li class="toctree-l2"><a class="reference internal" href="gpp_random_test.html">gpp_random_test</a></li>
<li class="toctree-l2"><a class="reference internal" href="gpp_optimizer_parameters.html">gpp_optimizer_parameters</a></li>
<li class="toctree-l2"><a class="reference internal" href="gpp_expected_improvement_demo.html">gpp_expected_improvement_demo</a></li>
<li class="toctree-l2"><a class="reference internal" href="gpp_random.html">gpp_random</a></li>
<li class="toctree-l2"><a class="reference internal" href="gpp_geometry_test.html">gpp_geometry_test</a></li>
<li class="toctree-l2"><a class="reference internal" href="gpp_linear_algebra.html">gpp_linear_algebra</a></li>
<li class="toctree-l2"><a class="reference internal" href="gpp_heuristic_expected_improvement_optimization_test.html">gpp_heuristic_expected_improvement_optimization_test</a></li>
<li class="toctree-l2"><a class="reference internal" href="gpp_linear_algebra_test.html">gpp_linear_algebra_test</a></li>
<li class="toctree-l2"><a class="reference internal" href="gpp_model_selection.html">gpp_model_selection</a></li>
<li class="toctree-l2"><a class="reference internal" href="gpp_optimization.html">gpp_optimization</a></li>
<li class="toctree-l2"><a class="reference internal" href="gpp_covariance_test.html">gpp_covariance_test</a></li>
<li class="toctree-l2"><a class="reference internal" href="gpp_mock_optimization_objective_functions.html">gpp_mock_optimization_objective_functions</a></li>
<li class="toctree-l2"><a class="reference internal" href="gpp_python.html">gpp_python</a></li>
<li class="toctree-l2"><a class="reference internal" href="gpp_model_selection_test.html">gpp_model_selection_test</a></li>
<li class="toctree-l2"><a class="reference internal" href="gpp_hyper_and_EI_demo.html">gpp_hyper_and_EI_demo</a></li>
<li class="toctree-l2"><a class="reference internal" href="gpp_python_gaussian_process.html">gpp_python_gaussian_process</a></li>
<li class="toctree-l2"><a class="reference internal" href="gpp_common.html">gpp_common</a></li>
</ul>
</li>
</ul>

        
      </div>
      &nbsp;
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap">

      
      <nav class="wy-nav-top" role="navigation" aria-label="top navigation">
        <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
        <a href="index.html">MOE</a>
      </nav>


      
      <div class="wy-nav-content">
        <div class="rst-content">
          <div role="navigation" aria-label="breadcrumbs navigation">
  <ul class="wy-breadcrumbs">
    <li><a href="index.html">Docs</a> &raquo;</li>
      
          <li><a href="cpp_tree.html">C++ Files</a> &raquo;</li>
      
    <li>gpp_math_test</li>
      <li class="wy-breadcrumbs-aside">
        
          <a href="_sources/gpp_math_test.txt" rel="nofollow"> View page source</a>
        
      </li>
  </ul>
  <hr/>
</div>
          <div role="main">
            
  <div class="section" id="gpp-math-test">
<h1>gpp_math_test<a class="headerlink" href="#gpp-math-test" title="Permalink to this headline">¶</a></h1>
<p><strong>Contents:</strong></p>
<blockquote>
<div><ol class="arabic simple">
<li><a class="reference internal" href="#gpp-math-test-hpp">gpp_math_test.hpp</a></li>
<li><a class="reference internal" href="#gpp-math-test-cpp">gpp_math_test.cpp</a></li>
</ol>
</div></blockquote>
<div class="section" id="gpp-math-test-hpp">
<h2>gpp_math_test.hpp<a class="headerlink" href="#gpp-math-test-hpp" title="Permalink to this headline">¶</a></h2>
<p></p>
<p><p>Functions for testing gpp_math&#8217;s GP and EI functionality.</p>
<p>Tests are broken into two main groups:</p>
<ul class="simple">
<li>ping (unit) tests for GP outputs (mean, cholesky/variance) and EI (for the general and one sample cases)</li>
<li>unit + integration tests for optimization methods</li>
</ul>
<p>The ping tests are set up the same way as the ping tests in gpp_covariance_test; using the function evaluator and ping
framework defined in gpp_test_utils.</p>
<p>There is also a consistency check between general MC-based EI calculation and the analytic one sample case.</p>
<p>Finally, we have tests for EI optimization.  These include multithreading tests (verifying that each core
does what is expected) as well as integration tests for EI optimization.  Unit tests for optimizers live in
gpp_optimization_test.hpp/cpp.  These integration tests use constructed data but exercise all the
same code paths used for hyperparameter optimization in production.</p>
 </p>
<p><p id="project0namespaceoptimal__learning"><em>namespace</em> <strong>optimal_learning</strong></p>
<blockquote>
<div><p></p>
<p></p>
<em>Enums</em><blockquote>
<div><p><span class="target" id="project0namespaceoptimal__learning_1a3521d0351193ea3c97ddc7d085d8f65e"></span><strong>ExpectedImprovementEvaluationMode enum</strong></p>
<blockquote>
<div><p></p>
<p><p>Enum for specifying which EI evaluation mode to test.</p>
 </p>
<p><em>Values:</em></p>
<ul class="breatheenumvalues">
<li><tt class="first docutils literal"><span class="pre">kAnalytic</span></tt><tt class="docutils literal"> <span class="pre">=</span> <span class="pre">=</span> <span class="pre">0</span></tt> - <p>test analytic evaluation </p>
</li>
<li><tt class="first docutils literal"><span class="pre">kMonteCarlo</span></tt><tt class="docutils literal"> <span class="pre">=</span> <span class="pre">=</span> <span class="pre">1</span></tt> - <p>test monte-carlo evaluation </p>
</li>
</ul>
</div></blockquote>
</div></blockquote>
</div></blockquote>
</p>
</div>
<div class="section" id="gpp-math-test-cpp">
<h2>gpp_math_test.cpp<a class="headerlink" href="#gpp-math-test-cpp" title="Permalink to this headline">¶</a></h2>
<p></p>
<p><p>Routines to test the functions in gpp_math.cpp.</p>
<p>The tests verify GaussianProcess, ExpectedImprovementEvaluator (+OnePotentialSample), and EI optimization from gpp_math.cpp.</p>
<ol class="arabic">
<li><p class="first">Ping testing (verifying analytic gradient computation against finite difference approximations)</p>
<ol class="loweralpha">
<li><p class="first">Following gpp_covariance_test.cpp, we define classes (PingGPMean + other GP ping, PingExpectedImprovement) for
evaluating those functions + their spatial gradients.</p>
<p>Some Pingable classes for GP functions are less general than their gpp_covariance_test or
gpp_model_selection_test counterparts, since GP derivative functions sometimes return sparse
or incomplete data (e.g., gradient of mean returned as a vector instead of a diagonal matrix; gradient of variance
only differentiates wrt a single point at a time); hence we need specialized handlers for testing.</p>
</li>
<li><p class="first">Ping for derivative accuracy (PingGPComponentTest, PingEITest); these unit test the analytic derivatives.</p>
</li>
</ol>
</li>
<li><p class="first">Monte-Carlo EI vs analytic EI validation: the monte-carlo versions are run to &#8220;high&#8221; accuracy and checked against
analytic formulae when applicable</p>
</li>
<li><p class="first">Gradient Descent: using polynomials and other simple fucntions with analytically known optima
to verify that the algorithm(s) underlying EI optimization are performing correctly.</p>
</li>
<li><p class="first">Single-threaded vs multi-threaded EI optimization validation: single and multi-threaded runs are checked to have the same
output.</p>
</li>
<li><p class="first">End-to-end test of the EI optimization process for the analytic and monte-carlo cases.  These tests use constructed
data for inputs but otherwise exercise the same code paths used for EI optimization in production.</p>
</li>
</ol>
 </p>
<em>Variables</em><blockquote>
<div><p><span class="target" id="project0gpp__math__test_8cpp_1af9bc72c8bcde2f1bfb5118e46ccb70d9"></span>constexpr char const *const <strong>kName</strong></p>
<blockquote>
<div><p></p>
<p></p>
</div></blockquote>
<p><span class="target" id="project0gpp__math__test_8cpp_1a844805bf936642eb8849d76b506abf8d"></span>int <strong>dim_</strong></p>
<blockquote>
<div><p>spatial dimension (e.g., entries per point of <tt class="docutils literal"><span class="pre">points_sampled</span></tt>) </p>
<p></p>
</div></blockquote>
<p><span class="target" id="project0gpp__math__test_8cpp_1a8a0bfacdd989fd91df2533b967c4b400"></span>int <strong>num_to_sample_</strong></p>
<blockquote>
<div><p>number of points currently being sampled </p>
<p>number of potential future samples; gradients are evaluated wrt these points (i.e., the &#8220;q&#8221; in q,p-EI) </p>
</div></blockquote>
<p><span class="target" id="project0gpp__math__test_8cpp_1a91da453a97415e9ff83c56f28f946b1d"></span>int <strong>num_sampled_</strong></p>
<blockquote>
<div><p>number of points in <tt class="docutils literal"><span class="pre">points_sampled</span></tt> </p>
<p></p>
</div></blockquote>
<p><span class="target" id="project0gpp__math__test_8cpp_1ad79f16c4e922363b7dd24698078837cd"></span>bool <strong>gradients_already_computed_</strong></p>
<blockquote>
<div><p>whether gradients been computed and storedwhether this class is ready for use </p>
<p></p>
</div></blockquote>
<p><span class="target" id="project0gpp__math__test_8cpp_1a96b0b32da7445069bf7ccd89b3f7924f"></span>std::vector&lt; double &gt; <strong>noise_variance_</strong></p>
<blockquote>
<div><p><tt class="docutils literal"><span class="pre">\sigma_n^2</span></tt>, the noise variance </p>
<p></p>
</div></blockquote>
<p><span class="target" id="project0gpp__math__test_8cpp_1a3c092218ce7325670a9ea3462a2b439f"></span>std::vector&lt; double &gt; <strong>points_sampled_</strong></p>
<blockquote>
<div><p>coordinates of already-sampled points, <tt class="docutils literal"><span class="pre">X</span></tt> </p>
<p></p>
</div></blockquote>
<p><span class="target" id="project0gpp__math__test_8cpp_1a3f526cf6cf08b7ec8c01e3df7b346d9e"></span>std::vector&lt; double &gt; <strong>points_sampled_value_</strong></p>
<blockquote>
<div><p>function values at points_sampled, <tt class="docutils literal"><span class="pre">y</span></tt> </p>
<p></p>
</div></blockquote>
<p><span class="target" id="project0gpp__math__test_8cpp_1af5bd8a12a5e9c15b129c09f0b0a09dd6"></span>std::vector&lt; double &gt; <strong>grad_mu_</strong></p>
<blockquote>
<div><p>the gradient of the GP mean evaluated at union_of_points, wrt union_of_points[0:num_to_sample] </p>
<p></p>
</div></blockquote>
<p><span class="target" id="project0gpp__math__test_8cpp_1a7bd28304ec7ba2769288311d9ab04c45"></span>SquareExponential <strong>sqexp_covariance_</strong></p>
<blockquote>
<div><p>covariance class (for computing covariance and its gradients) </p>
<p></p>
</div></blockquote>
<p><span class="target" id="project0gpp__math__test_8cpp_1a8f705919a254a72825a818e0f38222aa"></span>GaussianProcess <strong>gaussian_process_</strong></p>
<blockquote>
<div><p>gaussian process used for computations </p>
<p></p>
</div></blockquote>
<p><span class="target" id="project0gpp__math__test_8cpp_1abfcefe973c16edc3e9858d2a2ad0b3e4"></span>std::vector&lt; double &gt; <strong>grad_variance_</strong></p>
<blockquote>
<div><p>the gradient of the GP variance evaluated at union_of_points, wrt union_of_points[0:num_to_sample] </p>
<p>the gradient of the cholesky factorization of the GP variance evaluated at union_of_points, wrt union_of_points[0:num_to_sample] </p>
</div></blockquote>
<p><span class="target" id="project0gpp__math__test_8cpp_1a9918be8edf385deef72da109fbad9d38"></span>int <strong>num_being_sampled_</strong></p>
<blockquote>
<div><p>number of points being sampled concurrently (i.e., the &#8220;p&#8221; in q,p-EI) </p>
<p>number of points being sampled concurrently (i.e., the &#8220;p&#8221; in q,p-EI). Must be 0 for the analytic case. </p>
</div></blockquote>
<p><span class="target" id="project0gpp__math__test_8cpp_1aae4e7c76ff5d56a320c310c26405c5c5"></span>std::vector&lt; double &gt; <strong>points_being_sampled_</strong></p>
<blockquote>
<div><p>points that are being sampled in concurrently experiments </p>
<p></p>
</div></blockquote>
<p><span class="target" id="project0gpp__math__test_8cpp_1a148453eca18e1b13be63c702f82344bc"></span>std::vector&lt; double &gt; <strong>grad_EI_</strong></p>
<blockquote>
<div><p>the gradient of EI at union_of_points, wrt union_of_points[0:num_to_sample] </p>
<p></p>
</div></blockquote>
<p><span class="target" id="project0gpp__math__test_8cpp_1a2a7394b01158edd1c162685b6f659031"></span>ExpectedImprovementEvaluator <strong>ei_evaluator_</strong></p>
<blockquote>
<div><p>expected improvement evaluator object that specifies the parameters &amp; GP for EI evaluation </p>
<p></p>
</div></blockquote>
</div></blockquote>
<p><p id="project0namespaceoptimal__learning"><em>namespace</em> <strong>optimal_learning</strong></p>
<blockquote>
<div><p></p>
<p></p>
<em>Functions</em><blockquote>
<div><p><span class="target" id="project0namespaceoptimal__learning_1ad2566804276c165381fb287cd6ec0357"></span><div class="line-block">
<div class="line">int <strong>PingGPMeanTest</strong>()</div>
</div>
</p>
<blockquote>
<div><p></p>
<p><p><p>Pings the gradients (spatial) of the GP mean 50 times with randomly generated test cases</p>
<dl class="docutils">
<dt><strong>Returns</strong>:</dt>
<dd>number of ping/test failures</dd>
</dl>
</p>
<p><p>Checks that the gradients (spatial) of the GP mean are computed correctly.</p>
<dl class="docutils">
<dt><strong>Returns</strong>:</dt>
<dd>number of test failures: 0 if all is working well.</dd>
</dl>
 </p>
</p>
</div></blockquote>
<p><span class="target" id="project0namespaceoptimal__learning_1ac882d0ffac53bdbb799ff0374df472e6"></span><div class="line-block">
<div class="line">int <strong>PingGPVarianceTest</strong>()</div>
</div>
</p>
<blockquote>
<div><p></p>
<p><p><p>Pings the gradients (spatial) of the GP variance 50 times with randomly generated test cases</p>
<dl class="docutils">
<dt><strong>Returns</strong>:</dt>
<dd>number of ping/test failures</dd>
</dl>
</p>
<p><p>Checks that the gradients (spatial) of the GP variance are computed correctly.</p>
<dl class="docutils">
<dt><strong>Returns</strong>:</dt>
<dd>number of test failures: 0 if all is working well.</dd>
</dl>
 </p>
</p>
</div></blockquote>
<p><span class="target" id="project0namespaceoptimal__learning_1a0c841805de83a6c1e5f1251e668dd3ae"></span><div class="line-block">
<div class="line">int <strong>PingGPCholeskyVarianceTest</strong>()</div>
</div>
</p>
<blockquote>
<div><p></p>
<p><p><p>Wrapper to ping the gradients (spatial) of the cholesky factorization.</p>
<dl class="docutils">
<dt><strong>Returns</strong>:</dt>
<dd>number of ping/test failures</dd>
</dl>
</p>
<p><p>Checks that the gradients (spatial) of the cholesky factorization of GP variance are computed correctly.</p>
<dl class="docutils">
<dt><strong>Returns</strong>:</dt>
<dd>number of test failures: 0 if all is working well.</dd>
</dl>
 </p>
</p>
</div></blockquote>
<p><span class="target" id="project0namespaceoptimal__learning_1aabcf1a1293a6f1af68aeaf46c8343b5e"></span><div class="line-block">
<div class="line">template &lt; typename EIEvaluator &gt;</div>
<div class="line"><a class="reference internal" href="gpp_common.html#project0gpp__common_8hpp_1abda439d29ae03a473c1167e47159ae90"><em>OL_WARN_UNUSED_RESULT</em></a>  int <strong>PingEITest</strong>(int num_to_sample, int num_being_sampled, double epsilon, double tolerance_fine, double tolerance_coarse, double input_output_ratio)</div>
</div>
</p>
<blockquote>
<div><p></p>
<p><p>Pings the gradients (spatial) of the EI 50 times with randomly generated test cases
Works with various EI evaluators (e.g., MC, analytic formulae)</p>
<dl class="docutils">
<dt><strong>Parameters</strong>:</dt>
<dd><table class="first last docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">num_to_sample:</th><td class="field-body">number of potential future samples; gradients are evaluated wrt these points (i.e., the &#8220;q&#8221; in q,p-EI)</td>
</tr>
<tr class="field-even field"><th class="field-name" colspan="2">num_being_sampled:</th></tr>
<tr class="field-even field"><td>&nbsp;</td><td class="field-body">number of points being sampled in concurrent experiments (i.e., the &#8220;p&#8221; in q,p-EI)</td>
</tr>
<tr class="field-odd field"><th class="field-name">epsilon:</th><td class="field-body">coarse, fine <tt class="docutils literal"><span class="pre">h</span></tt> sizes to use in finite difference computation</td>
</tr>
<tr class="field-even field"><th class="field-name">tolerance_fine:</th><td class="field-body">desired amount of deviation from the exact rate</td>
</tr>
<tr class="field-odd field"><th class="field-name" colspan="2">tolerance_coarse:</th></tr>
<tr class="field-odd field"><td>&nbsp;</td><td class="field-body">maximum allowable abmount of deviation from the exact rate</td>
</tr>
<tr class="field-even field"><th class="field-name" colspan="2">input_output_ratio:</th></tr>
<tr class="field-even field"><td>&nbsp;</td><td class="field-body">for <tt class="docutils literal"><span class="pre">||analytic_gradient||/||input||</span> <span class="pre">&lt;</span> <span class="pre">input_output_ratio</span></tt>, ping testing is not performed, see PingDerivative()</td>
</tr>
</tbody>
</table>
</dd>
<dt><strong>Returns</strong>:</dt>
<dd>number of ping/test failures</dd>
</dl>
 </p>
</div></blockquote>
<p><span class="target" id="project0namespaceoptimal__learning_1a8d255f440001e46b4aa9ccb6b22ab9d0"></span><div class="line-block">
<div class="line">int <strong>PingEIGeneralTest</strong>()</div>
</div>
</p>
<blockquote>
<div><p></p>
<p><p><p>Pings the gradients (spatial) of the EI 50 times with randomly generated test cases</p>
<dl class="docutils">
<dt><strong>Returns</strong>:</dt>
<dd>number of ping/test failures</dd>
</dl>
</p>
<p><p>Checks that the gradients (spatial) of Expected Improvement are computed correctly.</p>
<dl class="docutils">
<dt><strong>Returns</strong>:</dt>
<dd>number of test failures: 0 if all is working well.</dd>
</dl>
 </p>
</p>
</div></blockquote>
<p><span class="target" id="project0namespaceoptimal__learning_1a2a089b95230132f337756422097dab59"></span><div class="line-block">
<div class="line">int <strong>PingEIOnePotentialSampleTest</strong>()</div>
</div>
</p>
<blockquote>
<div><p></p>
<p><p><p>Pings the gradients (spatial) of the EI (one potential sample special case) 50 times with randomly generated test cases</p>
<dl class="docutils">
<dt><strong>Returns</strong>:</dt>
<dd>number of ping/test failures</dd>
</dl>
</p>
<p><p>Checks the gradients (spatial) of Expected Improvement (in the special case of only 1 potential sample) are computed correctly.</p>
<dl class="docutils">
<dt><strong>Returns</strong>:</dt>
<dd>number of test failures: 0 if all is working well.</dd>
</dl>
 </p>
</p>
</div></blockquote>
<p><span class="target" id="project0namespaceoptimal__learning_1a462dd5b27f3d3431be48058fc52c1040"></span><div class="line-block">
<div class="line">int <strong>EIOnePotentialSampleEdgeCasesTest</strong>()</div>
</div>
</p>
<blockquote>
<div><p></p>
<p><p>Test cases where analytic EI would attempt to compute 0/0 without variance lower bounds.</p>
<p>The bounds are OnePotentialSampleExpectedImprovementEvaluator::kMinimumVarianceEI and
kMinimumVarianceGradEI. See those class docs for more details.</p>
<p>These particular test cases arose from plotting EI (easy since dim = 1) and checking
that EI and grad_EI were being computed appropriately at the specified locations.
The test cases are purposely simple; the requirement was that they trigger behavior
that would result in 0/0 without minimum variance thresholds.</p>
<p>Without the aforementioned thresholds, 1D analytic EI could attempt
<tt class="docutils literal"><span class="pre">0/0</span> <span class="pre">=</span> <span class="pre">(best_so_far</span> <span class="pre">-</span> <span class="pre">gp_mean)</span> <span class="pre">/</span> <span class="pre">sqrt(gp_variance)</span></tt>
The easiest way to do cause these conditions is to compute EI at (or near) one of
points_sampled such that <tt class="docutils literal"><span class="pre">gp_mean</span> <span class="pre">==</span> <span class="pre">best_so_far</span></tt> and <tt class="docutils literal"><span class="pre">gp_variance</span> <span class="pre">==</span> <span class="pre">0</span></tt>.
(Although these conditions can arise elsewhere; try plotting the test case in the code.)</p>
<dl class="docutils">
<dt><strong>Returns</strong>:</dt>
<dd>number of test failures</dd>
</dl>
 </p>
</div></blockquote>
<p><span class="target" id="project0namespaceoptimal__learning_1a93f04186e225f179d8ef489eeee6d0b1"></span><div class="line-block">
<div class="line">int <strong>RunEIConsistencyTests</strong>()</div>
</div>
</p>
<blockquote>
<div><p></p>
<p><p><p>Generates a set of 50 random test cases for expected improvement with only one potential sample.
The general EI (which uses MC integration) is evaluated to reasonably high accuracy (while not taking too long to run)
and compared against the analytic formula version for consistency.  The gradients (spatial) of EI are also checked.</p>
<dl class="docutils">
<dt><strong>Returns</strong>:</dt>
<dd>number of cases where analytic and monte-carlo EI do not match</dd>
</dl>
</p>
<p><p>Tests that the general EI + grad EI computation (using MC integration) is consistent
with the special analytic case of EI when there is only <em>ONE</em> potential point
to sample.</p>
<dl class="docutils">
<dt><strong>Returns</strong>:</dt>
<dd>number of test failures: 0 if all is working well.</dd>
</dl>
 </p>
</p>
</div></blockquote>
<p><span class="target" id="project0namespaceoptimal__learning_1a365b49c6aea21f6e951876109f265b11"></span><div class="line-block">
<div class="line">int <strong>RunGPTests</strong>()</div>
</div>
</p>
<blockquote>
<div><p></p>
<p><p>Runs a battery of tests for the GP and EI functions, including ping tests for:</p>
<ul class="simple">
<li>GP mean</li>
<li>GP variance</li>
<li>cholesky decomposition of the GP variance</li>
<li>Expected Improvement</li>
<li>Expected Improvement special case: only <em>ONE</em> potential point to sample</li>
</ul>
<p>and edge case testing for:</p>
<ul class="simple">
<li>1D Analytic Expected Improvement</li>
</ul>
<dl class="docutils">
<dt><strong>Returns</strong>:</dt>
<dd>number of test failures: 0 if all is working well.</dd>
</dl>
 </p>
</div></blockquote>
<p><span class="target" id="project0namespaceoptimal__learning_1a32ac5e4a053a50aeca391b9ea4d9f48e"></span><div class="line-block">
<div class="line">int <strong>MultithreadedEIOptimizationTest</strong>(ExpectedImprovementEvaluationMode ei_mode)</div>
</div>
</p>
<blockquote>
<div><p></p>
<p><p><p>Tests that single &amp; multithreaded EI optimization produce <em>the exact same</em> results.</p>
<p>We do this by first setting up EI optimization in a single threaded scenario with 2 starting points and 2 random number generators.
Optimization is run one from starting point 0 with RNG 0, and then again from starting point 1 with RNG 1.</p>
<p>Then we run the optimization multithreaded (with 2 threads) over both starting points simultaneously.  One of the threads
will see the winning (point, RNG) pair from the single-threaded won.  Hence one result point will match with the single threaded
results exactly.</p>
<p>Then we re-run the multithreaded optimization, swapping the position of the RNGs and starting points.  If thread 0 won in the
previous test, thread 1 will win here (and vice versa).</p>
<p>Note that it&#8217;s tricky to run single-threaded optimization over both starting points simultaneously because we won&#8217;t know which
(point, RNG) pair won (which is required to ascertain the &#8216;winner&#8217; since we are not computing EI accurately enough to avoid
error).</p>
</p>
<p><p>Checks that multithreaded EI optimization behaves the same way that single threaded does.</p>
<dl class="docutils">
<dt><strong>Parameters</strong>:</dt>
<dd><table class="first last docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">ei_mode:</th><td class="field-body">ei evaluation mode to test (analytic or monte carlo)</td>
</tr>
</tbody>
</table>
</dd>
<dt><strong>Returns</strong>:</dt>
<dd>number of test failures: 0 if EI multi/single threaded optimization are consistent</dd>
</dl>
 </p>
</p>
</div></blockquote>
<p><span class="target" id="project0namespaceoptimal__learning_1a0ddfa942ae8f71adc6b4511cf58cfcfb"></span><div class="line-block">
<div class="line">int <strong>ExpectedImprovementOptimizationMultipleSamplesTest</strong>()</div>
</div>
</p>
<blockquote>
<div><p></p>
<p><p><p>At the moment, this test is very bare-bones.  It checks:</p>
<ol class="arabic simple">
<li>method succeeds</li>
<li>points returned are all inside the specified domain</li>
<li>points returned are not within epsilon of each other (i.e., distinct)</li>
<li>result of gradient-descent optimization is <em>no worse</em> than result of a random search</li>
<li>final grad EI is sufficiently small</li>
</ol>
<p>The test sets up a toy problem by repeatedly drawing from a GP with made-up hyperparameters.
Then it runs EI optimization, attempting to sample 3 points simultaneously.</p>
</p>
<p><p>Checks that ComputeOptimalPointsToSample works on a tensor product domain.
This test exercises the the code tested in:
ExpectedImprovementOptimizationTest(kTensorProduct, ei_mode)
for <tt class="docutils literal"><span class="pre">ei_mode</span> <span class="pre">=</span> <span class="pre">{kAnalytic,</span> <span class="pre">kMonteCarlo}</span></tt>.</p>
<p>This test checks the generation of multiple, simultaneous experimental points to sample.</p>
<dl class="docutils">
<dt><strong>Returns</strong>:</dt>
<dd>number of test failures: 0 if EI optimization is working properly</dd>
</dl>
 </p>
</p>
</div></blockquote>
<p><span class="target" id="project0namespaceoptimal__learning_1ace6dc96a918f8f32ca469ba96212e730"></span><div class="line-block">
<div class="line">int <strong>EvaluateEIAtPointListTest</strong>()</div>
</div>
</p>
<blockquote>
<div><p></p>
<p><p>Tests EvaluateEIAtPointList (computes EI at a specified list of points, multithreaded).
Checks that the returned best point is in fact the best.
Verifies multithreaded consistency.</p>
<dl class="docutils">
<dt><strong>Returns</strong>:</dt>
<dd>number of test failures: 0 if function evaluation is working properly</dd>
</dl>
 </p>
</div></blockquote>
<p><span class="target" id="project0namespaceoptimal__learning_1a78c70d1826b95e2065604988fc8b7f4d"></span><div class="line-block">
<div class="line">int <strong>ExpectedImprovementOptimizationTest</strong>(DomainTypes domain_type, ExpectedImprovementEvaluationMode ei_mode)</div>
</div>
</p>
<blockquote>
<div><p></p>
<p><p>Checks that EI optimization is working on tensor product or simplex domain using
analytic or monte-carlo EI evaluation.</p>
<dl class="docutils">
<dt><strong>Parameters</strong>:</dt>
<dd><table class="first last docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">domain_type:</th><td class="field-body">type of the domain to test on (e.g., tensor product, simplex)</td>
</tr>
<tr class="field-even field"><th class="field-name">ei_mode:</th><td class="field-body">ei evaluation mode to test (analytic or monte carlo)</td>
</tr>
</tbody>
</table>
</dd>
<dt><strong>Returns</strong>:</dt>
<dd>number of test failures: 0 if EI optimization is working properly</dd>
</dl>
 </p>
</div></blockquote>
</div></blockquote>
</div></blockquote>
</p>
</div>
</div>


          </div>
          <footer>
  
    <div class="rst-footer-buttons" role="navigation" aria-label="footer navigation">
      
        <a href="gpp_python_expected_improvement.html" class="btn btn-neutral float-right" title="gpp_python_expected_improvement"/>Next <span class="fa fa-arrow-circle-right"></span></a>
      
      
        <a href="gpp_test_utils_test.html" class="btn btn-neutral" title="gpp_test_utils_test"><span class="fa fa-arrow-circle-left"></span> Previous</a>
      
    </div>
  

  <hr/>

  <div role="contentinfo">
    <p>
        &copy; Copyright 2012-2014 Yelp. MOE is licensed under the Apache License, Version 2.0: http://www.apache.org/licenses/LICENSE-2.0.
    </p>
  </div>

  <a href="https://github.com/snide/sphinx_rtd_theme">Sphinx theme</a> provided by <a href="https://readthedocs.org">Read the Docs</a>
</footer>
        </div>
      </div>

    </section>

  </div>
  


  

    <script type="text/javascript">
        var DOCUMENTATION_OPTIONS = {
            URL_ROOT:'./',
            VERSION:'0.1.0',
            COLLAPSE_INDEX:false,
            FILE_SUFFIX:'.html',
            HAS_SOURCE:  true
        };
    </script>
      <script type="text/javascript" src="_static/jquery.js"></script>
      <script type="text/javascript" src="_static/underscore.js"></script>
      <script type="text/javascript" src="_static/doctools.js"></script>
      <script type="text/javascript" src="http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>

  

  
  
    <script type="text/javascript" src="_static/js/theme.js"></script>
  

  
  
  <script type="text/javascript">
      jQuery(function () {
          SphinxRtdTheme.StickyNav.enable();
      });
  </script>
   

</body>
</html>